{
  "cells": [
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:30.609786Z",
          "start_time": "2025-07-06T19:27:30.603227Z"
        },
        "id": "7117191b989792a2"
      },
      "cell_type": "code",
      "source": [
        "#!pip install -r requirements.txt\n",
        "!pip install numpy==1.24.3 thefuzz"
      ],
      "id": "7117191b989792a2",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bCm_71vJTXgI"
      },
      "id": "bCm_71vJTXgI",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:41.724973Z",
          "start_time": "2025-07-06T19:27:30.726726Z"
        },
        "id": "1b649e23df0e3be7"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import kagglehub\n",
        "import torch\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"arashnic/book-recommendation-dataset\")\n",
        "# path = '../dataset'\n",
        "\n",
        "books = pd.read_csv(f\"{path}/Books.csv\")\n",
        "ratings = pd.read_csv(f\"{path}/Ratings.csv\")\n",
        "users= pd.read_csv(f\"{path}/Users.csv\")\n",
        "\n",
        "book_of_interest = 'don quixote'"
      ],
      "id": "1b649e23df0e3be7",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "f5e3bd3f8d60c89f"
      },
      "cell_type": "markdown",
      "source": [
        "Find LOTR books in the database"
      ],
      "id": "f5e3bd3f8d60c89f"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:42.202018Z",
          "start_time": "2025-07-06T19:27:42.037887Z"
        },
        "id": "4f87ba9160069596"
      },
      "cell_type": "code",
      "source": [
        "lotr_books = books[books[\"Book-Title\"].str.contains(book_of_interest, case=False)]\n",
        "lotr_books.head()"
      ],
      "id": "4f87ba9160069596",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "8e8a2d1ad7949bc0"
      },
      "cell_type": "markdown",
      "source": [
        "Books"
      ],
      "id": "8e8a2d1ad7949bc0"
    },
    {
      "metadata": {
        "id": "248f4539d23c29a"
      },
      "cell_type": "markdown",
      "source": [
        "Get rid of images and nan values"
      ],
      "id": "248f4539d23c29a"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:42.719836Z",
          "start_time": "2025-07-06T19:27:42.401716Z"
        },
        "id": "3f7476c878d988d0"
      },
      "cell_type": "code",
      "source": [
        "books.drop(['Image-URL-S', 'Image-URL-L'], axis=1, inplace=True) # leave one image column for later visualization\n",
        "print(books.isna().any(axis=1).sum()) # there only 4 incomplete rows, I'll simply drop them\n",
        "books.dropna(inplace=True)"
      ],
      "id": "3f7476c878d988d0",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "fd3db189e79cd041"
      },
      "cell_type": "markdown",
      "source": [
        "I will deduplicate on (Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher') tuples later, as there may be ratings that I would otherwise get rid off if i do deduplication in books table now"
      ],
      "id": "fd3db189e79cd041"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:42.928435Z",
          "start_time": "2025-07-06T19:27:42.764084Z"
        },
        "id": "25838d91bb4e5c88"
      },
      "cell_type": "code",
      "source": [
        "num_duplicates = books.duplicated(['Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher']).sum()\n",
        "print(f\"Duplicate books {100*num_duplicates/len(books):.2f}%\")"
      ],
      "id": "25838d91bb4e5c88",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:43.209168Z",
          "start_time": "2025-07-06T19:27:42.976965Z"
        },
        "id": "85ca5fb11015cd13"
      },
      "cell_type": "code",
      "source": [
        "books['Year-Of-Publication'] = pd.to_numeric(books['Year-Of-Publication'], errors='coerce')\n",
        "print(books['Year-Of-Publication'].isna().sum())\n",
        "books = books.fillna({'Year-Of-Publication': books['Year-Of-Publication'].mean()}) # impute with mean"
      ],
      "id": "85ca5fb11015cd13",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:43.720588Z",
          "start_time": "2025-07-06T19:27:43.235945Z"
        },
        "id": "9e1c09be876825e5"
      },
      "cell_type": "code",
      "source": [
        "author_count = books['Book-Author'].value_counts().reset_index(name='Count').sort_values('Count', ascending=False).head(10)\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
        "ax.bar(author_count['Book-Author'], author_count['Count'], color='salmon')\n",
        "ax.set_xticks(range(len(author_count)))\n",
        "ax.set_xticklabels(author_count['Book-Author'], rotation=45, ha='right')\n",
        "ax.set_title('Top Authors')"
      ],
      "id": "9e1c09be876825e5",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "c5ad74894cac72a5"
      },
      "cell_type": "markdown",
      "source": [
        "Users"
      ],
      "id": "c5ad74894cac72a5"
    },
    {
      "cell_type": "code",
      "source": [
        "users['Location'].nunique()"
      ],
      "metadata": {
        "id": "MhtaO9BCm5at"
      },
      "id": "MhtaO9BCm5at",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:43.984609Z",
          "start_time": "2025-07-06T19:27:43.752254Z"
        },
        "id": "7bd0466ee2c8377"
      },
      "cell_type": "code",
      "source": [
        "users['Location'] = users['Location'].apply(lambda x: x.split(',')[-1].lower().strip()) # replace (city, region, country) with just the country\n",
        "users['Location'] = users['Location'].str.replace(r'[!./@\"]', '', regex=True)\n",
        "users['Location'].nunique()"
      ],
      "id": "7bd0466ee2c8377",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(users['Location'].unique()).loc[lambda s: s.str.contains('spa', case=False, na=False)]"
      ],
      "metadata": {
        "id": "j6O-YcQuif5O"
      },
      "id": "j6O-YcQuif5O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Locations are still pretty dirty. There are around 200 recognized countries in the world and the data we have tells us that there are 617. There are many invalid places like \"somewhere in space\" or country names not written in english, that have a typo, written in incorrect format and so on..."
      ],
      "metadata": {
        "id": "DJS4CtQqp4mj"
      },
      "id": "DJS4CtQqp4mj"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:44.028454Z",
          "start_time": "2025-07-06T19:27:44.007137Z"
        },
        "id": "9dfe6bc618dd8bd2"
      },
      "cell_type": "code",
      "source": [
        "users.isna().sum()"
      ],
      "id": "9dfe6bc618dd8bd2",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:44.115080Z",
          "start_time": "2025-07-06T19:27:44.103936Z"
        },
        "id": "16ba59bc200c837d"
      },
      "cell_type": "code",
      "source": [
        "print(f\"Missing ages {100*users['Age'].isna().sum() / len(users['Age']):.2f}%\")"
      ],
      "id": "16ba59bc200c837d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:44.356140Z",
          "start_time": "2025-07-06T19:27:44.265650Z"
        },
        "id": "58baf92ff50d27cd"
      },
      "cell_type": "code",
      "source": [
        "users.fillna({'Age': 0}, inplace=True)\n",
        "users.loc[users['Age'] <= 3, 'Age'] = 0\n",
        "mean = users['Age'][users['Age'] <= 3].mean()\n",
        "users['Age'] = users['Age'].replace(0, mean) # impute by mean"
      ],
      "id": "58baf92ff50d27cd",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "89c9c10ff0c61630"
      },
      "cell_type": "markdown",
      "source": [
        "Ratings"
      ],
      "id": "89c9c10ff0c61630"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:44.585236Z",
          "start_time": "2025-07-06T19:27:44.565138Z"
        },
        "id": "c7c8ffaa707b6649"
      },
      "cell_type": "code",
      "source": [
        "ratings.head()"
      ],
      "id": "c7c8ffaa707b6649",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:45.035299Z",
          "start_time": "2025-07-06T19:27:44.689398Z"
        },
        "id": "e2b70d436fbef0db"
      },
      "cell_type": "code",
      "source": [
        "plt.hist(ratings['Book-Rating'], color='salmon', bins=range(1, 12), edgecolor='black', align='left')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of explicit book ratings')\n",
        "plt.xticks(range(1, 11))\n",
        "plt.show()"
      ],
      "id": "e2b70d436fbef0db",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "d072a99afb6c8147"
      },
      "cell_type": "markdown",
      "source": [
        "We have explicit and implicit feedback..."
      ],
      "id": "d072a99afb6c8147"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:45.789975Z",
          "start_time": "2025-07-06T19:27:45.063463Z"
        },
        "id": "b805927ceee25251"
      },
      "cell_type": "code",
      "source": [
        "ratings_explicit = ratings[ratings['Book-Rating'] != 0] # choose only explicit ratings for now\n",
        "\n",
        "book_ratings = ratings_explicit.merge(books.drop('Image-URL-M', axis=1), on='ISBN')\n",
        "implicit = 1 - len(book_ratings) / len(ratings)\n",
        "print(f\"Implicit ratings percentage: {implicit:.2%}\")"
      ],
      "id": "b805927ceee25251",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "9a02bf35f62647e0"
      },
      "cell_type": "markdown",
      "source": [
        "Get the user-book rating matrix"
      ],
      "id": "9a02bf35f62647e0"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:46.106273Z",
          "start_time": "2025-07-06T19:27:45.907902Z"
        },
        "id": "69da136ca840f8d1"
      },
      "cell_type": "code",
      "source": [
        "complete_df = book_ratings.merge(users, on=\"User-ID\") # create a triplet dataframe of users;rankings;books dataframes"
      ],
      "id": "69da136ca840f8d1",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the metadata combined with ratings, we can deduplicate and clean up the data some more"
      ],
      "metadata": {
        "id": "YLZuFQPqrz9_"
      },
      "id": "YLZuFQPqrz9_"
    },
    {
      "cell_type": "code",
      "source": [
        "complete_df['Book-Title'] = complete_df['Book-Title'].str.lower()\n",
        "complete_df['Book-Author'] = complete_df['Book-Author'].str.lower()\n",
        "complete_df.duplicated({'Book-Title', 'Book-Author', 'User-ID'}).sum() / len(complete_df)"
      ],
      "metadata": {
        "id": "PQh5EeK2sDk4"
      },
      "id": "PQh5EeK2sDk4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_df = complete_df.groupby(['Book-Title', 'Book-Author', 'User-ID'], as_index=False).agg({\n",
        "    'Book-Rating': 'mean',\n",
        "    **{col: 'first' for col in complete_df.columns if col not in ['Book-Title', 'Book-Author', 'User-ID', 'Book-Rating']}\n",
        "})"
      ],
      "metadata": {
        "id": "xHEZSSmhz_To"
      },
      "id": "xHEZSSmhz_To",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "741bd7098965dc4e"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate the sparsity of our user-book ratings"
      ],
      "id": "741bd7098965dc4e"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:46.143900Z",
          "start_time": "2025-07-06T19:27:46.129123Z"
        },
        "id": "15f1c3335fd785ac"
      },
      "cell_type": "code",
      "source": [
        "def compute_sparsity(ratings_df):\n",
        "    n_users = ratings_df['User-ID'].nunique()\n",
        "    n_books = ratings_df['ISBN'].nunique()\n",
        "    print(f\"Number of users: {n_users}\")\n",
        "    print(f\"Number of books: {n_books}\")\n",
        "\n",
        "    total_possible = n_users * n_books\n",
        "    actual_ratings = len(ratings_df)\n",
        "    print(f\"Actual ratings: {actual_ratings}\")\n",
        "    print(f\"Total possible ratings: {total_possible}\")\n",
        "\n",
        "    sparsity = 1 - (actual_ratings / total_possible)\n",
        "    print(f\"Sparsity of the user-book ratings: {sparsity:.7f}\")\n",
        "\n",
        "    return sparsity"
      ],
      "id": "15f1c3335fd785ac",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:27:46.415850Z",
          "start_time": "2025-07-06T19:27:46.267064Z"
        },
        "id": "1d7a266aeb0fd987"
      },
      "cell_type": "code",
      "source": [
        "sparsity = compute_sparsity(complete_df)"
      ],
      "id": "1d7a266aeb0fd987",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "537a27026a235667"
      },
      "cell_type": "markdown",
      "source": [
        "Our data is very sparse. To try and mitgate this, we can filter out less popular books and inexperienced users"
      ],
      "id": "537a27026a235667"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:28:55.273778Z",
          "start_time": "2025-07-06T19:28:54.947491Z"
        },
        "id": "cc7114ee5885a70d"
      },
      "cell_type": "code",
      "source": [
        "mask_users = complete_df.groupby('User-ID')['Book-Rating'] \\\n",
        "                        .transform('size') >= 10\n",
        "mask_books = complete_df.groupby('ISBN')['Book-Rating'] \\\n",
        "                         .transform('size') >= 10\n",
        "\n",
        "filtered_df = complete_df[mask_users & mask_books]"
      ],
      "id": "cc7114ee5885a70d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:28:57.505297Z",
          "start_time": "2025-07-06T19:28:57.481615Z"
        },
        "id": "1280b5bd1ff05eaf"
      },
      "cell_type": "code",
      "source": [
        "sparsity = compute_sparsity(filtered_df)"
      ],
      "id": "1280b5bd1ff05eaf",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "fd4c5f7c5c12c09c"
      },
      "cell_type": "markdown",
      "source": [
        "I will train a classical SVD model and use the learned book vectors in latent space to do item to item similarity."
      ],
      "id": "fd4c5f7c5c12c09c"
    },
    {
      "metadata": {
        "id": "4461c25845987b87"
      },
      "cell_type": "markdown",
      "source": [
        "If a root mean square error is around 1.5 on average. We can safely say that the average rating prediction of our model is off by no more than 1.5, since rmse is greater or equal to the mean absolute error"
      ],
      "id": "4461c25845987b87"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T18:51:41.873276Z",
          "start_time": "2025-07-06T18:51:35.456854Z"
        },
        "id": "c77bbe2f7594fd5f"
      },
      "cell_type": "code",
      "source": [
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import KFold\n",
        "from surprise import accuracy\n",
        "\n",
        "data_df = filtered_df[['User-ID', 'ISBN', 'Book-Rating']].copy()\n",
        "\n",
        "# create the model from surprise library and perform 5-fold cross-validation\n",
        "min_c, max_c = data_df['Book-Rating'].min(), data_df['Book-Rating'].max()\n",
        "reader = Reader(rating_scale=(min_c, max_c))\n",
        "data = Dataset.load_from_df(data_df, reader)\n",
        "model = SVD(n_factors=50)\n",
        "\n",
        "rmse_test, rmse_train = [], []\n",
        "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "\n",
        "for fold, (train, test) in enumerate(kf.split(data)):\n",
        "    model.fit(train)\n",
        "\n",
        "    preds = model.test(test)\n",
        "    rmse_curr = accuracy.rmse(preds)\n",
        "    rmse_test.append(rmse_curr)\n",
        "\n",
        "    train_testset = train.build_testset()\n",
        "    preds = model.test(train_testset)\n",
        "    rmse_curr = accuracy.rmse(preds, verbose=False)\n",
        "    rmse_train.append(rmse_curr)\n",
        "\n",
        "print(f\"Mean test set RMSE: {np.mean(rmse_test):.4f}\")\n",
        "print(f\"Mean train set RMSE: {np.mean(rmse_train):.4f}\")"
      ],
      "id": "c77bbe2f7594fd5f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T18:51:42.087429Z",
          "start_time": "2025-07-06T18:51:41.917056Z"
        },
        "id": "e259589eb0c92699"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "isbn2title = {\n",
        "    isbn: title.strip().lower()\n",
        "    for isbn, title in zip(books['ISBN'], books['Book-Title'])\n",
        "}\n",
        "\n",
        "inner2title = {}\n",
        "for inner_id in range(train.n_items):\n",
        "    try:\n",
        "        raw_id = train.to_raw_iid(inner_id)\n",
        "        inner2title[inner_id] = isbn2title.get(raw_id, \"\").lower()\n",
        "    except ValueError:\n",
        "        continue\n",
        "\n",
        "title2inner = {\n",
        "    title: iid\n",
        "    for iid, title in inner2title.items()\n",
        "    if title\n",
        "}\n",
        "\n",
        "def book2book_retrieval(book_title, model, title2inner, inner2title, top_n=10):\n",
        "    key = book_title.lower()\n",
        "    if key not in title2inner:\n",
        "        # find a partial match\n",
        "        for inner_id, title in inner2title.items():\n",
        "            if book_title.lower() in title:\n",
        "                key = title\n",
        "                break\n",
        "        else:\n",
        "            print(f\"No match found for '{book_title}'\")\n",
        "            return []\n",
        "        print(f\"No exact match for '{book_title}' found. Showing results for '{key}' instead.\")\n",
        "\n",
        "    inner_id = title2inner[key]\n",
        "\n",
        "    # cosine sim\n",
        "    q = model.qi[inner_id]\n",
        "    q_norm = q / np.linalg.norm(q)\n",
        "    db_norm = model.qi / np.linalg.norm(model.qi, axis=1, keepdims=True)\n",
        "    sims = db_norm.dot(q_norm)\n",
        "\n",
        "    recs = [\n",
        "        (inner2title[iid], round(score, 3))\n",
        "        for iid, score in enumerate(sims)\n",
        "        if iid != inner_id\n",
        "    ]\n",
        "    recs.sort(key=lambda x: x[1], reverse=True)\n",
        "    return recs[:top_n]"
      ],
      "id": "e259589eb0c92699",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T18:51:42.258505Z",
          "start_time": "2025-07-06T18:51:42.254908Z"
        },
        "id": "499170665d1ad126"
      },
      "cell_type": "code",
      "source": [
        "book_of_interest = 'the lord of the rings'\n",
        "print(title2inner[book_of_interest])"
      ],
      "id": "499170665d1ad126",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T18:51:42.584299Z",
          "start_time": "2025-07-06T18:51:42.484399Z"
        },
        "id": "b6690337dda6a14c"
      },
      "cell_type": "code",
      "source": [
        "book2book_retrieval(book_of_interest, model, title2inner, inner2title, top_n=10)"
      ],
      "id": "b6690337dda6a14c",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "a54cdf568ed5cadb"
      },
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "#\n",
        "# with open(\"models/svd_model/model2.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(model, f)\n",
        "#\n",
        "# with open(\"models/svd_model/inner2title2.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(inner2title, f)"
      ],
      "id": "a54cdf568ed5cadb",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "[EASE](https://arxiv.org/pdf/1905.03375), but with explicit ratings"
      ],
      "metadata": {
        "id": "_V5UkCu15GFW"
      },
      "id": "_V5UkCu15GFW"
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = ratings['Book-Rating'][ratings['Book-Rating'] > 0].mean() # the mean of explicit rankings\n",
        "ratings_implicit = ratings[\n",
        "    (ratings['Book-Rating'] == 0) | (ratings['Book-Rating'] >= threshold)\n",
        "].copy()\n",
        "\n",
        "ratings_implicit['Book-Rating'] = ratings_implicit['Book-Rating'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "ratings_implicit.head()"
      ],
      "metadata": {
        "id": "VwqN4DeIP6JA"
      },
      "id": "VwqN4DeIP6JA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_ratings = ratings_implicit.merge(books.drop('Image-URL-M', axis=1), on='ISBN')\n",
        "complete_df = book_ratings.merge(users, on='User-ID')\n",
        "compute_sparsity(complete_df)"
      ],
      "metadata": {
        "id": "S5oPf3XeRXG0"
      },
      "id": "S5oPf3XeRXG0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_users = complete_df.groupby('User-ID')['Book-Rating'] \\\n",
        "                        .transform('size') >= 3\n",
        "mask_books = complete_df.groupby('ISBN')['Book-Rating'] \\\n",
        "                         .transform('size') >= 10\n",
        "\n",
        "filtered_df = complete_df[mask_users & mask_books]\n",
        "compute_sparsity(filtered_df)"
      ],
      "metadata": {
        "id": "lqMNEY3pSRDi"
      },
      "id": "lqMNEY3pSRDi",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:18:44.815269Z",
          "start_time": "2025-07-06T19:18:40.481376Z"
        },
        "id": "8b30b35cab72bca7"
      },
      "cell_type": "code",
      "source": [
        "unique_isbns = filtered_df['ISBN'].unique()\n",
        "isbn_to_id = {isbn: idx for idx, isbn in enumerate(unique_isbns)}\n",
        "\n",
        "id_to_isbn = {idx: isbn for isbn, idx in isbn_to_id.items()}\n",
        "filtered_df['ISBN_ID'] = filtered_df['ISBN'].map(isbn_to_id)\n",
        "\n",
        "X_id_df = (\n",
        "    pd.pivot(\n",
        "        data=filtered_df,\n",
        "        columns='ISBN_ID',\n",
        "        index='User-ID',\n",
        "        values='Book-Rating'\n",
        "    )\n",
        "    .fillna(0)\n",
        ")\n",
        "\n",
        "X = torch.tensor(X_id_df.fillna(0).values, dtype=torch.float32)"
      ],
      "id": "8b30b35cab72bca7",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:18:47.013701Z",
          "start_time": "2025-07-06T19:18:46.976650Z"
        },
        "id": "fdf678911efc3647"
      },
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "id": "fdf678911efc3647",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-06T19:06:34.928049Z",
          "start_time": "2025-07-06T19:06:24.760304Z"
        },
        "id": "eed34f1ce197e206"
      },
      "cell_type": "code",
      "source": [
        "I = torch.eye(X.shape[1])\n",
        "reg = 100 # regularization hyperparameter\n",
        "P_hat = torch.inverse(X.T @ X + reg * I)\n",
        "B_hat = I - P_hat * torch.diag(I / torch.diag(P_hat))\n",
        "B_hat = B_hat.fill_diagonal_(0)\n",
        "print(B_hat.shape)"
      ],
      "id": "eed34f1ce197e206",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "dff2d121e7ac1943"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# import pickle\n",
        "\n",
        "# with open(\"model10.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(B_hat, f)\n",
        "\n",
        "# with open(\"df10.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(filtered_df, f)\n"
      ],
      "id": "dff2d121e7ac1943"
    },
    {
      "cell_type": "code",
      "source": [
        "from thefuzz import process\n",
        "\n",
        "def ease_item2item(B, book_name, df, score_cutoff=90, top_n=10):\n",
        "    unique_titles = list(dict.fromkeys(df['Book-Title'].str.lower()))\n",
        "    unique_isbns = df['ISBN'].unique().tolist()\n",
        "\n",
        "    best_match = process.extractOne(book_name.lower(), unique_titles)\n",
        "    if not best_match or best_match[1] < score_cutoff:\n",
        "        return None\n",
        "\n",
        "    # Get the matched row\n",
        "    print(f'Matched book: {best_match[0]}')\n",
        "    matched_ISBNs = df[df['Book-Title'].str.lower() == best_match[0]]['ISBN']\n",
        "    if matched_ISBNs.empty:\n",
        "        return None\n",
        "\n",
        "    inner_id = unique_isbns.index(matched_ISBNs.iloc[0])\n",
        "    top_indices = torch.topk(B[inner_id], top_n).indices\n",
        "    top_isbns = [unique_isbns[i] for i in top_indices]\n",
        "    titles = filtered_df[filtered_df['ISBN'].isin(top_isbns)]['Book-Title'].unique().tolist()\n",
        "\n",
        "    return top_indices"
      ],
      "metadata": {
        "id": "r4ykoo4lDIu3"
      },
      "id": "r4ykoo4lDIu3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_of_interest = 'the lord of the rings'\n",
        "titles = ease_item2item(B_hat, book_of_interest, filtered_df)\n",
        "for title in titles:\n",
        "    print(title)"
      ],
      "metadata": {
        "id": "WOcQUpHDThDk"
      },
      "id": "WOcQUpHDThDk",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "18e409dc272ecd10"
      },
      "cell_type": "markdown",
      "source": [
        "Since the feedback is so sparse, I'll try a NN based approach incorporate book and user metadata. For that, I need to do some more data preprocessing"
      ],
      "id": "18e409dc272ecd10"
    },
    {
      "metadata": {
        "id": "e83ca127633d59e6"
      },
      "cell_type": "code",
      "source": [
        "# split_idx = int(0.8 * len(filtered_df))\n",
        "# train_df = filtered_df[:split_idx]\n",
        "# test_df = filtered_df[split_idx:]\n",
        "\n",
        "# train = torch.utils.data.DataLoader(Loader(train_df, config['year_intervals'], config['age_intervals']),\n",
        "#                                     batch_size=config['batch_size'], shuffle=True)\n",
        "# test = torch.utils.data.DataLoader(Loader(test_df, config['year_intervals'], config['age_intervals']),\n",
        "#                                     batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "# nn_model = Recommender(\n",
        "#     filtered_df['User-ID'].nunique(),\n",
        "#     filtered_df['ISBN'].nunique(),\n",
        "#     filtered_df['Location'].nunique() * len(config['age_intervals']),\n",
        "#     filtered_df['Book-Author'].nunique() * len(config['year_intervals']))\n",
        "\n",
        "# optimizer = torch.optim.AdamW(nn_model.parameters(), lr=1e-3, weight_decay=1e-3)"
      ],
      "id": "e83ca127633d59e6",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "8af3bcb472d5dd57"
      },
      "cell_type": "code",
      "source": [
        "# for i in range(config['epochs']):\n",
        "#     nn_model.train()\n",
        "#     train_losses = []\n",
        "#     for (x, y) in train:\n",
        "#         optimizer.zero_grad()\n",
        "#         y_pred = nn_model(x)\n",
        "#         metric = torch.sqrt(torch.nn.functional.mse_loss(y_pred.sigmoid() * 10, y))\n",
        "#         loss = torch.nn.functional.binary_cross_entropy_with_logits(y_pred, y / 10)\n",
        "#         train_losses.append(metric.item())\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#     nn_model.eval()\n",
        "#     test_losses = []\n",
        "#     with torch.no_grad():\n",
        "#         for (x, y) in test:\n",
        "#             y_pred = nn_model(x).squeeze(-1)\n",
        "#             loss = torch.sqrt(torch.nn.functional.mse_loss(y_pred.sigmoid() * 10, y))\n",
        "#             test_losses.append(loss.item())\n",
        "\n",
        "#     train_rmse = np.mean(train_losses)\n",
        "#     test_rmse = np.mean(test_losses)\n",
        "#     print(f\"Epoch {i+1}/{config['epochs']} - Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}\")"
      ],
      "id": "8af3bcb472d5dd57",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "c771d5a442eeccb7"
      },
      "cell_type": "code",
      "source": [
        "# def book2book_retrieval(book_title, train, model, book2idx, idx2book, top_n=10):\n",
        "#     key = book_title.lower()\n",
        "#     if key not in title2inner:\n",
        "#         # find a partial match\n",
        "#         for inner_id, title in inner2title.items():\n",
        "#             if book_title.lower() in title:\n",
        "#                 key = title\n",
        "#                 break\n",
        "#         else:\n",
        "#             print(f\"No match found for '{book_title}'\")\n",
        "#             return []\n",
        "#         print(f\"No exact match for '{book_title}' found. Showing results for '{key}' instead.\")\n",
        "\n",
        "#     inner_id = title2inner[key] # the inner key in this case is actually the ISBN\n",
        "\n",
        "#     # cosine sim\n",
        "#     author = train.ratings.loc[train.ratings['ISBN'] == inner_id, 'Book-Author'].iloc[0]\n",
        "#     year_bin = train.ratings.loc[train.ratings['ISBN'] == inner_id, 'Year-Of-Publication'].iloc[0]\n",
        "#     sims = model.item_embeddings()\n",
        "\n",
        "#     recs = [\n",
        "#         (inner2title[iid], round(score, 3))\n",
        "#         for iid, score in enumerate(sims)\n",
        "#         if iid != inner_id\n",
        "#     ]\n",
        "#     recs.sort(key=lambda x: x[1], reverse=True)\n",
        "#     return recs[:top_n]"
      ],
      "id": "c771d5a442eeccb7",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "bb6a165ceb6b8efb"
      },
      "cell_type": "code",
      "source": [
        "# book2book_retrieval()"
      ],
      "id": "bb6a165ceb6b8efb",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}